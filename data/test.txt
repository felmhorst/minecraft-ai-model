def calculate_gradient_penalty(
        discriminator: Discriminator3D,
        real_occupancy: torch.Tensor,    # [B,1,D,H,W], long or float
        real_textures: torch.Tensor,     # [B,D,H,W], long (texture IDs)
        fake_occupancy_logits: torch.Tensor,  # [B,1,D,H,W] (generator output logits)
        fake_texture_logits: torch.Tensor,    # [B,NUM_TEXTURES,D,H,W] (generator output logits)
        label_embeddings: torch.Tensor,
        device: str = 'cpu',
        eps_shape=None
) -> torch.Tensor:
    """
    Gradient penalty that ignores texture-gradients where interpolated occupancy ~ 0.
    - real_occupancy: {0,1} (or float) shape [B,1,D,H,W]
    - real_textures: texture ids shape [B,D,H,W]
    - fake_occupancy_logits, fake_texture_logits: raw generator outputs (logits)
    """

    batch_size = real_occupancy.size(0)
    # epsilon scalar per-sample (broadcasted to volume)
    epsilon = torch.rand(batch_size, 1, 1, 1, 1, device=device)

    # --- Build real_x and fake_x in the same representation the discriminator expects ---
    # real texture embeddings: [B, D, H, W, E] -> permute to [B, E, D, H, W]
    real_tex_emb = discriminator.texture_embedding(real_textures).permute(0, 4, 1, 2, 3).float()

    # fake texture embedding: compute expected embedding using soft mixture over texture classes
    fake_texture_probs = torch.softmax(fake_texture_logits / TEMPERATURE, dim=1)  # [B, C, D, H, W]
    # combine probs with embedding weights: result [B, E, D, H, W]
    fake_tex_emb = torch.einsum("bcdhw,ce->bedhw", fake_texture_probs, discriminator.texture_embedding.weight)

    # fake occupancy probabilities (sigmoid of logits)
    fake_occ_prob = torch.sigmoid(fake_occupancy_logits).float()  # [B,1,D,H,W]

    # make sure real occupancy is float
    real_occ_float = real_occupancy.float()  # [B,1,D,H,W]

    # concatenate occupancy channel + texture embedding channels -> [B, 1+E, D, H, W]
    real_x = torch.cat([real_occ_float, real_tex_emb], dim=1)
    fake_x = torch.cat([fake_occ_prob,   fake_tex_emb], dim=1)

    # interpolate
    interpolated = epsilon * real_x + (1 - epsilon) * fake_x
    interpolated.requires_grad_(True)

    # --- critic output on interpolated features ---
    # we need a discriminator method that accepts already embedded inputs.
    # Use the discriminator forward with already_embedded=True (we assume it accepts this),
    # or add a small helper that computes features->score from an embedding input.
    d_interpolated = discriminator(interpolated, label_embeddings, already_embedded=True)
    # d_interpolated: [B]

    # compute gradients of critic output wrt interpolated input
    gradients = torch.autograd.grad(
        outputs=d_interpolated,
        inputs=interpolated,
        grad_outputs=torch.ones_like(d_interpolated),
        create_graph=True,
        retain_graph=True,
        only_inputs=True
    )[0]  # shape [B, 1+E, D, H, W]

    # --- compute per-voxel squared norms across channels ---
    # gradients_sq_sum_per_voxel: [B, D, H, W]
    gradients_sq = gradients.pow(2)
    # sum across channel dimension (channel 0 is occupancy, channels 1: are texture-emb)
    per_voxel_sqnorm = gradients_sq.sum(dim=1)  # [B, D, H, W]

    # --- separate occupancy-channel gradient contribution (we'll always include it) ---
    occupancy_grad_sq = gradients_sq[:, 0:1, ...].sum(dim=[1, 2, 3])  # [B] sum over channel=occupancy then voxels
    # occupancy_grad_sq is squared L2 norm contributed by occupancy channel across entire volume

    # --- texture grad contribution per voxel (exclude occupancy channel) ---
    texture_per_voxel_sq = gradients_sq[:, 1:, ...].sum(dim=1)  # [B, D, H, W]

    # occupancy value for interpolated input (continuous in [0,1])
    occupancy_interp = interpolated[:, 0, ...]  # [B, D, H, W]

    # weight each voxel's texture grad-norm by occupancy_interp (so empty voxels contribute ~0)
    weighted_texture_sq = texture_per_voxel_sq * occupancy_interp  # [B, D, H, W]

    # sum over voxels to get per-sample texture grad squared norm
    texture_grad_sq_per_sample = weighted_texture_sq.sum(dim=[1, 2, 3])  # [B]

    # combine occupancy channel norm (always included) + weighted texture norm
    grad_norm_per_sample = torch.sqrt(occupancy_grad_sq + texture_grad_sq_per_sample + 1e-12)  # [B]

    # gradient penalty: enforce ||grad|| close to 1
    gradient_penalty = ((grad_norm_per_sample - 1) ** 2).mean()

    return gradient_penalty
